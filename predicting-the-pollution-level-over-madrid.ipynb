{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Ahmed Emam\n## Imm.Num 64821"},{"metadata":{},"cell_type":"markdown","source":"### Definition of task:\nAnalysis and prediction of air pollution in Madrid, Spain.\n1. Analyse the multivariate dataset:\na. Are there significant correlations between the pollutant parameters?\nb. The air quality can be described as the sum of all pollutants. Which parameters\nhave the biggest influence?\n2. Generate a time series with average monthly values for Madrid, which describes the air\nquality as the sum of all pollutants (9)!\na. In which months is the pollutant load greatest?\nb. Perform a comprehensive analysis of the generated time series!\nc. Choose a suitable stochastic model to model the time series and justify your\nselection!\nd. Perform a prediction of the time series (including 95% confidence interval) for\nthe following 2 years (until 04/2020) based on y"},{"metadata":{},"cell_type":"markdown","source":"## Task 1:\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"%matplotlib  inline\n! pip install missingno\n! pip install fbprophet\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport glob\nimport missingno as msno\n# from fbprophet import Prophet\n\nfrom datetime import datetime, timedelta\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom itertools import product\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error \n\nfrom collections import defaultdict\nfrom scipy.stats import boxcox\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller, kpss\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\nfrom matplotlib import pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"3db6cb6583a491213f8fd3bdba4473c5714614c5","trusted":true},"cell_type":"code","source":"\nsns.set(rc={\"figure.figsize\": (20,10), \"axes.titlesize\" : 18, \"axes.labelsize\" : 12, \n            \"xtick.labelsize\" : 14, \"ytick.labelsize\" : 14 })","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c206e23a75f19a27c901978c2abae63ce6fc604"},"cell_type":"markdown","source":"# Read in data"},{"metadata":{"_kg_hide-input":true,"_uuid":"5963aa73e567b7a79197ee6f6f371c0192d8b1ad","trusted":true},"cell_type":"code","source":"\n\nframe = pd.read_csv('../input/madriddddd/madrid_mean_1h_raw.csv')\n\nframe.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0626100747e5602dc85fe06ae742b789c5a600d3"},"cell_type":"markdown","source":"# Missing data?"},{"metadata":{"_kg_hide-input":true,"_uuid":"b2e2d9ea21f1e33e4fc885268d0e30ceab39b88b","trusted":true},"cell_type":"code","source":"msno.matrix(frame);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"cbc8229346467d5093738f33e3027483f135b0c2","trusted":true},"cell_type":"code","source":"msno.bar(frame);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"we don't have missing values"},{"metadata":{},"cell_type":"markdown","source":"## statistical analysis summary for the data frame \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"measures= frame\nmeasures.describe().round(decimals=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most dominant pollutants are NO_2 and O_3\n\n \n if we gave a look at the mean values of each of the pollutants, we can conclude that the most dominant polutants are No2 and O3 respectively, given that our assumptions that we the summation of the pollutants content is our goal. so the pollutant with the highest mean will be the dominant"},{"metadata":{},"cell_type":"markdown","source":"_____________"},{"metadata":{},"cell_type":"markdown","source":"### checking the correlations between different features (pollutants)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(measures.corr(), square=True, annot=True, cmap='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### we can see the highest correlation between BEN, CO, EBE and TOL, and that O_3 is the only with negative correlation value"},{"metadata":{},"cell_type":"markdown","source":" Positive Correlation: means that if feature A increases then feature B also increases or if feature A decreases then feature B also decreases. Both features move in tandem and they have a linear relationship.\n Negative Correlation: means that if feature A increases then feature B decreases and vice versa.\n No Correlation: No relationship between those two attributes."},{"metadata":{},"cell_type":"markdown","source":" #### Correlation Matrix explaination:\n Each of those correlation types can exist in a spectrum represented by values from 0 to 1 where slightly or highly positive correlation features can be something like 0.5 or 0.7. If there is a strong and perfect positive correlation, then the result is represented by a correlation score value of 0.9 or 1.\n If there is a strong negative correlation, it will be represented by a value of -1.\n If your dataset has perfectly positive or negative attributes then there is a high chance that the performance of the model will be impacted by a problem called — “Multicollinearity”. Multicollinearity happens when one predictor variable in a multiple regression model can be linearly predicted from the others with a high degree of accuracy. This can lead to skewed or misleading results. Luckily, decision trees and boosted trees algorithms are immune to multicollinearity by nature. When they decide to split, the tree will choose only one of the perfectly correlated features. However, other algorithms like Logistic Regression or Linear Regression are not immune to that problem and you should fix it before training the model.\n \n ___________________________"},{"metadata":{},"cell_type":"markdown","source":"## Task 2 \n"},{"metadata":{},"cell_type":"markdown","source":"creating a sum column which will contain the summation of all pollutatnts values "},{"metadata":{"trusted":true},"cell_type":"code","source":"measures['sum'] = measures.sum(axis = 1, skipna = True) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to set the date as the index for the data frame\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"date =pd.to_datetime(measures['date'])\ndate_index =pd.DatetimeIndex(date.values)\nmeasures = measures.set_index(date_index)\nmeasures.drop('date',axis=1,inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate a time series with average monthly values for Madrid"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 5))\nSum = measures['sum']\n\nSum /= Sum.max(axis=0)\n\n(Sum.interpolate(method='time')\n           .rolling(window=24*30).mean()\n           .plot(ax=ax))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.dates import MonthLocator, DateFormatter\nimport matplotlib.ticker as ticker\nimport matplotlib.dates as mdates\nyears = mdates.YearLocator()   # every year\nmonths = mdates.MonthLocator()  # every month\nyears_fmt = mdates.DateFormatter('%Y')\nSum_avg_month = Sum.resample('M').mean()\nfig, ax = plt.subplots()\nax.plot(Sum_avg_month)\n\n# format the ticks\nax.xaxis.set_major_locator(years)\n#ax.xaxis.set_major_locator(months)\n#ax.xaxis.set_major_formatter(DateFormatter('%m'))\n\n\n\n\n\n# format the coords message box\n\n\nax.grid(True)\n\n# rotates and right aligns the x labels, and moves the bottom of the\n# axes up to make room for them\nfig.autofmt_xdate()\nplt.xticks(rotation='vertical')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_sum = measures['sum'].resample('M').mean().sort_values(ascending = False)\nprint(sorted_sum)\nsorted_sum_index = sorted_sum.index\nstring = [sorted_sum_index.strftime('%m')]\nflat_list = [] \n\nfor sublist in string: \n\n     for item in sublist: \n\n        flat_list.append(item)\nflat_list = list(map(int, flat_list))\nflat_list = pd.Series(flat_list)\nflat_list.describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"candidates = measures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"candidates['month'] = pd.to_datetime(candidates.index).month\ncandidates['year'] = pd.to_datetime(candidates.index).year\nsns.lineplot(x='month',y='sum',hue= 'year',data=candidates.query('year>2001'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Months with the highest value of pollutants are July and June\nfrom the previous 3 plots and statistical analysis of dates with the highest average values of pollutants we can see that we have a surge in the pollutants levels in mid year \n"},{"metadata":{},"cell_type":"markdown","source":"......................................................................................................................................................."},{"metadata":{},"cell_type":"markdown","source":"## now let's check the seasonality and decombose the spectrum of the time series"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight') \nplt.rcParams['xtick.labelsize'] = 20\nplt.rcParams['ytick.labelsize'] = 20\ndf=measures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmonthly_df = df.resample('M').mean()\nplt_monthly = monthly_df['sum']\nplt_monthly.plot(figsize=(15, 10))\nplt.title('Madrid Pollutants from 2001-2019', fontsize=25)\nplt.legend(loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adf_test(timeseries):\n    print ('Results of Dickey-Fuller Test:')\n    print('Null Hypothesis: Unit Root Present')\n    print('Test Statistic < Critical Value => Reject Null')\n    print('P-Value =< Alpha(.05) => Reject Null\\n')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput[f'Critical Value {key}'] = value\n    print (dfoutput, '\\n')\n\ndef kpss_test(timeseries, regression='c'):\n    # Whether stationary around constant 'c' or trend 'ct\n    print ('Results of KPSS Test:')\n    print('Null Hypothesis: Data is Stationary/Trend Stationary')\n    print('Test Statistic > Critical Value => Reject Null')\n    print('P-Value =< Alpha(.05) => Reject Null\\n')\n    kpsstest = kpss(timeseries, regression=regression)\n    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n    for key,value in kpsstest[3].items():\n        kpss_output[f'Critical Value {key}'] = value\n    print (kpss_output, '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install statsmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Results of Dickey-Fuller Test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nadf_test(plt_monthly)\nkpss_test(plt_monthly)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decomposition_df = pd.DataFrame(monthly_df['sum'])\nseasonal_a = seasonal_decompose(decomposition_df, model='additive')\nseasonal_m = seasonal_decompose(decomposition_df, model='multiplicative')\nfig_1 = seasonal_a.plot()\nfig_2 = seasonal_m.plot()\nfig_1.suptitle('Additive Seasonal Decomposition', fontsize=25)\nfig_1.set_figheight(10)\nfig_1.set_figwidth(20)\nfig_2.suptitle('Multiplicative Seasonal Decomposition', fontsize=25)\nfig_2.set_figheight(10)\nfig_2.set_figwidth(20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport statsmodels.api as sm\n\nimport statsmodels.formula.api as smf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_df = pd.DataFrame(monthly_df['sum'])\nsum_cycle, sum_trend =sm.tsa.filters.hpfilter(filter_df, lamb=129600)\nfilter_df['cycle'] = sum_cycle\nfilter_df['trend'] = sum_trend\n\nfilter_df.plot(figsize=(10, 5), title=' Pollutants Plot of Cycle and Trend')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Forecasting by Prophet"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt_monthly.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmonthly_df = df.resample('M').mean()\nmonthly_df['y'] = monthly_df['sum']\nmonthly_df['ds'] = monthly_df.index\nmonthly_df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\ndf = monthly_df\nm = Prophet(seasonality_mode='multiplicative').fit(df)\nfuture = m.make_future_dataframe(periods=356*2)\nfcst = m.predict(future)\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(fcst)\nfcst.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the forcasting ends in 12 may 2020 after 2 years"},{"metadata":{},"cell_type":"markdown","source":"### plotting only the monthly data ******"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(monthly_df['sum'],color = 'r', marker='o', label='actual monthly data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting both real data and forcasting together"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nm.plot(fcst,xlabel='time in year',uncertainty=False, plot_cap=False , ax = plt.axes())\nplt.plot(monthly_df['sum'],color = 'r', marker='o', label='actual monthly data')\nplt.legend()\n\n\n\nplt.title('pollution forcast over madrid')\nplt.ylabel('pollution level')\n\n\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}